{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Segmentation by RFM (Recency, Frequency, Monetary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from functools import wraps\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'OnlineRetail.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vp/k70yvwj57vd00y1yn6zl3mkr0000gn/T/ipykernel_5156/744719925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read excel file to dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OnlineRetail.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Turn letter to lower case for easy coding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OnlineRetail.xlsx'"
     ]
    }
   ],
   "source": [
    "# Read excel file to dataframe\n",
    "df = pd.read_excel('Online Retail.xlsx')\n",
    "# Turn letter to lower case for easy coding\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset United Kingdom only \n",
    "df = df[df.country == 'United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.description.isnull(), 'description'] = 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop customerid's null values since we are trying to cluster customer, and without customer id\n",
    "# we won't be able to know who is the customer. We can't impute missing values because this is a\n",
    "#primary key. \n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Decorator & Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decorator timer\n",
    "def timer(func):\n",
    "    \"\"\"A decorator that prints how long a function took to run\"\"\"\n",
    "    \n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        total = time.time() - start\n",
    "        print(f'{total:.2f}s runtime on {func.__name__} function')\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ClusterK class\n",
    "class Cluster:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @timer\n",
    "    def predict(self, n_clusters, data):\n",
    "        \"\"\"Use Kmeans to predict cluster for input data\"\"\"\n",
    "        \n",
    "        kmean = KMeans(n_clusters=n_clusters, max_iter=1000)\n",
    "        kmean.fit(data)\n",
    "        predictions = kmean.predict(data)\n",
    "        return predictions\n",
    "    \n",
    "    @timer   \n",
    "    def elbow(self, data):\n",
    "        \"\"\"Elbow method compute number of clusters and distance\n",
    "            Return:\n",
    "            INT(number of cluster)\n",
    "            INT(distance)       \n",
    "        \"\"\"\n",
    "        distance = []\n",
    "        k_range = range(1,10)\n",
    "        for k in k_range:\n",
    "            km = KMeans(n_clusters=k, max_iter=1000).fit(data)           \n",
    "            distance.append(km.inertia_)\n",
    "        return k_range, distance\n",
    "    \n",
    "    def plot_elbow(self, k_range, distance):\n",
    "        \"\"\"Plot elbow on lineplot\"\"\"\n",
    "        \n",
    "        sns.lineplot(k_range, distance, marker='o')\n",
    "        plt.xlabel('Number of Cluster'); plt.ylabel('Distance')\n",
    "        plt.title('Elbow Method for Optimal K')\n",
    "        plt.show()\n",
    "        \n",
    "    @timer   \n",
    "    def cluster_order(self, cluster_name, target_name, df, ascending):\n",
    "        \"\"\" Re-order cluster labels so labels looks neat and easy to understand.\n",
    "        Cluster 0 would be most favourable\n",
    "        \"\"\"\n",
    "        \n",
    "        df_new = df.groupby(cluster_name)[target_name].mean().reset_index()\n",
    "        df_new = df_new.sort_values(target_name, ascending=ascending).reset_index(drop=True)\n",
    "        df_new['index'] = df_new.index\n",
    "        df_final = pd.merge(df, df_new[[cluster_name, 'index']], on=cluster_name)\n",
    "        df_final.drop(cluster_name, axis=1, inplace=True)\n",
    "        df_final.rename(columns={'index': cluster_name}, inplace=True)\n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe by unique customer id\n",
    "user = pd.DataFrame(df['customerid'].unique(), columns=['customer_id'])\n",
    "\n",
    "# Subset recent invoice date by customer id as their purchase history\n",
    "purchase_history = df.groupby('customerid').invoicedate.max().reset_index()\n",
    "purchase_history.columns = ['customer_id', 'recent_purchase_date']\n",
    "\n",
    "# Compute number of days since their last purchase from recent date\n",
    "purchase_history['recency'] = (purchase_history['recent_purchase_date'].max() - purchase_history['recent_purchase_date']).dt.days\n",
    "\n",
    "# Merge user & purchase_history\n",
    "user = user.merge(purchase_history[['customer_id', 'recency']], on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer #17850 last purchase was 301 days from the most recent invoice date\n",
    "# Likewise, customer #12583 purchased a product 2 days ago from the most recent invoice date\n",
    "user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average recency is 91 days. However, the median is 49 days. This indicated a skewed distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(user.recency, rug=True)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Recency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate user's recency for cluster\n",
    "recency_df = user[['recency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate cluster\n",
    "cluster = Cluster()\n",
    "k_range, distance = cluster.elbow(recency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "cluster.plot_elbow(k_range, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 clusters seem to be our optimal. However, we will use 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and assign cluster for each customers\n",
    "recency_preds = cluster.predict(4, recency_df)\n",
    "\n",
    "user['recency_cluster'] = recency_preds\n",
    "user.groupby('recency_cluster')['recency'].describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cluster 0 is our most recent buyer, meanwhile cluster 3 & 2 tend to be inactive. The cluster isn't in order with 0, 2, 1, 3 from active to inactive, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cluster order function to re-order cluster for easy view\n",
    "user_df = cluster.cluster_order('recency_cluster', 'recency', user, False)\n",
    "user_df.groupby('recency_cluster')['recency'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the order of cluster_name has reflected its attritube from 0 as inactive to 3 as active. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulise clusters name by customer \n",
    "sns.lmplot(x='recency', y='customer_id', hue='recency_cluster', data=user_df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_frequency = df.groupby('customerid')['invoicedate'].count().reset_index()\n",
    "user_frequency.columns = ['customer_id', 'frequency']\n",
    "user_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(user_frequency.query('frequency < 500')['frequency'], rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.merge(user_df, user_frequency, on='customer_id')\n",
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.frequency.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_range, f_distance = cluster.elbow(user_df[['frequency']])\n",
    "cluster.plot_elbow(f_range, f_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and assign cluster for each customers\n",
    "frequency_preds = cluster.predict(4, user_df[['frequency']])\n",
    "\n",
    "user_df['frequency_cluster'] = frequency_preds\n",
    "user_df.groupby('frequency_cluster')['frequency'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = cluster.cluster_order('frequency_cluster', 'frequency', user_df, True)\n",
    "user_df.groupby('frequency_cluster')['frequency'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0 - 3 clusters as similar to recency. 3 is the most favourable as this cluster has the most frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monetary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revenue'] = df.quantity * df.unitprice\n",
    "user_revenue = df.groupby('customerid')['revenue'].sum().reset_index()\n",
    "user_revenue.columns = ['customer_id', 'revenue']\n",
    "user_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.merge(user_df, user_revenue, on='customer_id')\n",
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(user_df.query('revenue<10000')['revenue'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is negative values for revenue. an indication of refund or product return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_preds = cluster.predict(4, user_df[['revenue']])\n",
    "\n",
    "user_df['revenue_cluster'] = revenue_preds\n",
    "user_df.groupby('revenue_cluster')['revenue'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = cluster.cluster_order('revenue_cluster', 'revenue', user_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.groupby('revenue_cluster')['revenue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have re-ordered the cluster again as similar to above method with cluster 3 is the most favourable in term of monetary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have created 3 type of cluster (recency, frequency, monetary) with the higher value of cluster the better/favourable customer. Therefore, we can add these cluster value together to show the top customer for online retail dataset. The customer with the highest score indicated recent purchase, high purchase frequency(repeated purchase) and top spending.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['score'] = user_df['recency_cluster'] + user_df['frequency_cluster'] + user_df['revenue_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.groupby('score')['recency', 'frequency', 'revenue'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['segment'] = 'Low-Value'\n",
    "user_df.loc[user_df.score > 2, 'segment'] = 'Mid-Value'\n",
    "user_df.loc[user_df.score > 4, 'segment'] = 'High-Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "ax.scatter(np.log(user_df.query('segment == \"High-Value\"')['frequency']), np.log(user_df.query('segment == \"High-Value\"')['revenue']+1), marker='>', alpha=0.5, label='High')\n",
    "ax.scatter(np.log(user_df.query('segment == \"Mid-Value\"')['frequency']), np.log(user_df.query('segment == \"Mid-Value\"')['revenue']+1), marker='o', alpha=0.5, label='Mid')\n",
    "ax.scatter(np.log(user_df.query('segment == \"Low-Value\"')['frequency']), np.log(user_df.query('segment == \"Low-Value\"')['revenue']+1), marker='+', alpha=0.5, label='Low')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Revenue')\n",
    "fig.suptitle('Frequency vs Revenue by Customer Segmentation')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "ax.scatter(np.log(user_df.query('segment == \"High-Value\"')['recency']), np.log(user_df.query('segment == \"High-Value\"')['revenue']+1), marker='>', alpha=0.5, label='High')\n",
    "ax.scatter(np.log(user_df.query('segment == \"Mid-Value\"')['recency']), np.log(user_df.query('segment == \"Mid-Value\"')['revenue']+1), marker='o', alpha=0.5, label='Mid')\n",
    "ax.scatter(np.log(user_df.query('segment == \"Low-Value\"')['recency']), np.log(user_df.query('segment == \"Low-Value\"')['revenue']+1), marker='+', alpha=0.5, label='Low')\n",
    "ax.set_xlabel('Recency log(days)')\n",
    "ax.set_ylabel('Revenue log($)')\n",
    "fig.suptitle('Frequency vs Revenue by Customer Segmentation')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "ax.scatter(np.log(user_df.query('segment == \"High-Value\"')['recency']), np.log(user_df.query('segment == \"High-Value\"')['frequency']+1), marker='>', alpha=0.5, label='High')\n",
    "ax.scatter(np.log(user_df.query('segment == \"Mid-Value\"')['recency']), np.log(user_df.query('segment == \"Mid-Value\"')['frequency']+1), marker='o', alpha=0.5, label='Mid')\n",
    "ax.scatter(np.log(user_df.query('segment == \"Low-Value\"')['recency']), np.log(user_df.query('segment == \"Low-Value\"')['frequency']+1), marker='+', alpha=0.5, label='Low')\n",
    "ax.set_xlabel('Recency log(days)')\n",
    "ax.set_ylabel('Frequency')\n",
    "fig.suptitle('Frequency vs Revenue by Customer Segmentation')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_t = user_df[['score', 'segment', 'customer_id']]\n",
    "user_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = df.merge(user_df_t, left_on='customerid', right_on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.drop('customer_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.to_csv('online_retail_rfmscore.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
