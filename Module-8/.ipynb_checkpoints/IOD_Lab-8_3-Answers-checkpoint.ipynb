{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXUiceLiLNOv"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmJwFqq5LNOx"
   },
   "source": [
    "# Lab 8.3: Working with Text\n",
    "- Using [spaCy](https://spacy.io)\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I83eiiJqLNO0"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ecJn_1MLNO4"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import regex as re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsSgzr8MLNO9"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvyU9ZbtLNPA"
   },
   "outputs": [],
   "source": [
    "## Loading the data\n",
    "\n",
    "input_file = '../../../DATA/ncc-1701-D.txt'\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF9gBdpALNPE"
   },
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JImxUzrLNPG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5ePf_5bLNPK"
   },
   "source": [
    "## Work the data\n",
    "- if necessary or desired\n",
    "    - remove text or content, e.g. quotes (\") or metadata (===)\n",
    "    - add content or markers, e.g. (#FLAG, --NAME--)\n",
    "    - remove or convert special symbols, e.g. \"é\" to \"e\"\n",
    "    - remove or convert emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRq7VfoOLNPM"
   },
   "outputs": [],
   "source": [
    "text = re.sub(r'[=\"]', '', text)\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMG9Yim0LNPP"
   },
   "source": [
    "## Helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oIPRH3gLNPQ"
   },
   "outputs": [],
   "source": [
    "# create a bar chart of the frequency of the words in the text\n",
    "def plot_words(tokens, top = 30):\n",
    "    tokens_counter = Counter(tokens)\n",
    "    tok = [t for (t, _) in tokens_counter.most_common()]\n",
    "    val = [v for (_, v) in tokens_counter.most_common()]\n",
    "\n",
    "    plt.figure(figsize = (16, 6))\n",
    "    plt.bar(tok[:top], val[:top])\n",
    "    plt.title('Number of terms: %d' % len(tokens_counter))\n",
    "    plt.xticks(rotation = 90)\n",
    "    \n",
    "    for i, label in enumerate(val[:top]):\n",
    "        plt.text(i, label, label, ha='center', va='bottom') \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1FsFC6yLNPS"
   },
   "source": [
    "## spaCy model invocation and text processing\n",
    "spaCy does the processing of the text as part of the reading of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgM48u-dLNPU"
   },
   "outputs": [],
   "source": [
    "# load spaCy and the English model\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# process the text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8--KeYzLNPW"
   },
   "source": [
    "## Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7lVWo5DLNPe"
   },
   "outputs": [],
   "source": [
    "# only show the results\n",
    "# spaCy has done it already\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d| %r' % (i+1, t.text))\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gcg4Hkx4LNPh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_words(['%r' % t.text for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAtMzEZTLNPj"
   },
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOzudmrILNPq"
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "print('i | with stop words without')\n",
    "print('--| --------------- ------------')\n",
    "\n",
    "# for all the tokens\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d| %-15r %r' % (i+1, t.text, ('' if t.is_stop else t.text)))\n",
    "\n",
    "    # break after the first sentence\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2LoqLmULNPs"
   },
   "outputs": [],
   "source": [
    "plot_words(['%r' % t.text for t in doc if not (t.is_stop | t.is_punct)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uqME12uLNPu"
   },
   "source": [
    "## Check Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vD-BrcLALNPz"
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d|%-12r : %-5s %s' % (i+1, t.text, t.pos_, t.tag_))\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2d9a6QazLNP4"
   },
   "source": [
    "## Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "448zp9_vLNQC"
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "print('i | Token        Lemma')\n",
    "print('--| ------------ ------------')\n",
    "for i, t in enumerate(doc):\n",
    "    print('%2d| %-12r %r' % (i+1, t.text, t.lemma_))\n",
    "    if t.text == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-7pqVMxLNQD"
   },
   "outputs": [],
   "source": [
    "plot_words(['%r' % t.lemma_ for t in doc if not (t.is_stop | t.is_punct)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHUdgHM7LNQF"
   },
   "source": [
    "## Identify Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyOrZ42oLNQH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## spaCy\n",
    "for i, s in enumerate(doc.sents):\n",
    "    print('%2d: %s' % (i, re.sub(r'\\n+', '', s.text)))\n",
    "    if s.as_doc().ents:\n",
    "        print('-'*80)\n",
    "        for e in s.as_doc().ents:\n",
    "            print('%-11s: %s' % (e.label_, re.sub(r'\\n+', '', e.text)))\n",
    "    print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pML63M9KLNPX",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use nltk to find tokens\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "for i, t in enumerate(tokens[:25]):\n",
    "    print('%2d| %r' % (i+1, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5C3ituYLNPZ"
   },
   "outputs": [],
   "source": [
    "plot_words(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnY2rFzuLNPj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stopWords.sort()\n",
    "print(', '.join(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVwrtRZnLNPl"
   },
   "outputs": [],
   "source": [
    "# create a list of tokens withOUT the stop words\n",
    "# NOTE: see the `.lower()` method applied to token\n",
    "tokens_no_stop = [t for t in tokens if t.lower() not in stopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a82KBILRLNPm"
   },
   "outputs": [],
   "source": [
    "## NLTK\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "print('i | with stop words without')\n",
    "print('--| --------------- ------------')\n",
    "\n",
    "# for all the tokens\n",
    "while i < len(tokens):\n",
    "    # same word\n",
    "    if tokens[i] == tokens_no_stop[j]:\n",
    "        print('%2d| %-15r %r' % (i+1, tokens[i], tokens_no_stop[j]))\n",
    "        j += 1\n",
    "    # not the same word\n",
    "    else:\n",
    "        print('%2d| %-15r' % (i+1, tokens[i]))\n",
    "\n",
    "    # next word\n",
    "    i += 1\n",
    "    # break after the first sentence\n",
    "    if tokens[i-1] == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPtOoiwuLNPo"
   },
   "outputs": [],
   "source": [
    "plot_words(tokens_no_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRupju0sLNPv"
   },
   "outputs": [],
   "source": [
    "# define PoS\n",
    "pos_list = {\n",
    "    'CC':   'coordinating conjunction',\n",
    "    'CD':   'cardinal digit',\n",
    "    'DT':   'determiner',\n",
    "    'EX':   'existential there (like: \"there is\" ... think of it like \"there exists\")',\n",
    "    'FW':   'foreign word',\n",
    "    'IN':   'preposition/subordinating conjunction',\n",
    "    'JJ':   'adjective \"big\"',\n",
    "    'JJR':  'adjective, comparative \"bigger\"',\n",
    "    'JJS':  'adjective, superlative \"biggest\"',\n",
    "    'LS':   'list marker 1)',\n",
    "    'MD':   'modal could, will',\n",
    "    'NN':   'noun, singular \"desk\"',\n",
    "    'NNS':  'noun plural \"desks\"',\n",
    "    'NNP':  'proper noun, singular \"Harrison\"',\n",
    "    'NNPS': 'proper noun, plural \"Americans\"',\n",
    "    'PDT':  'predeterminer \"all the kids\"',\n",
    "    'POS':  'possessive ending parent\"s',\n",
    "    'PRP':  'personal pronoun I, he, she',\n",
    "    'PRP$': 'possessive pronoun my, his, hers',\n",
    "    'RB':   'adverb very, silently,',\n",
    "    'RBR':  'adverb, comparative better',\n",
    "    'RBS':  'adverb, superlative best',\n",
    "    'RP':   'particle give up',\n",
    "    'TO':   'to go \"to\" the store.',\n",
    "    'UH':   'interjection errrrrrrrm',\n",
    "    'VB':   'verb, base form take',\n",
    "    'VBD':  'verb, past tense took',\n",
    "    'VBG':  'verb, gerund/present participle taking',\n",
    "    'VBN':  'verb, past participle taken',\n",
    "    'VBP':  'verb, sing. present, non-3d take',\n",
    "    'VBZ':  'verb, 3rd person sing. present takes',\n",
    "    'WDT':  'wh-determiner which',\n",
    "    'WP':   'wh-pronoun who, what',\n",
    "    'WP$':  'possessive wh-pronoun whose',\n",
    "    'WRB':  'wh-abverb where, when',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asqUoCHgLNPx"
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "for i, t in enumerate(tagged[:25]):\n",
    "    print('%2d|%-12r : %-4s %s' % (i+1, t[0], t[1], (pos_list[t[1]] if t[1] in pos_list else '-')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL1vRUzxLNP2"
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "stemmed = ' '.join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAbriUsXLNP7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "wl = nltk.stem.WordNetLemmatizer()\n",
    "lemma = ' '.join([wl.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVIqX7HBLNP9"
   },
   "outputs": [],
   "source": [
    "## nltk\n",
    "dot = stemmed.find('.') + 1\n",
    "sl = stemmed[:dot].split()\n",
    "dot = lemma.find('.') + 1\n",
    "ll = lemma[:dot].split()\n",
    "\n",
    "print('i | Stem           Lemma')\n",
    "print('--| -------------- ------------')\n",
    "for i, p in enumerate(zip(sl, ll)):\n",
    "    print('%2d| %-12r   %-12r' % (i+1, p[0], p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eG4yOgwVLNP-"
   },
   "outputs": [],
   "source": [
    "plot_words(stemmed.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEJR57TYLNQA"
   },
   "outputs": [],
   "source": [
    "plot_words(lemma.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sw6fYdgXLNQG"
   },
   "outputs": [],
   "source": [
    "## Identify entities\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "\n",
    "for e in entities:\n",
    "    s = re.sub(r'[\\(\\)]', '', str(e))\n",
    "    if s.find('/NNP') > 0:\n",
    "        t = s.split()[0]\n",
    "        n = ' '.join([re.sub(r'/NNP', '', x) for x in s.split()[1:]])\n",
    "        print('%-12s: %s' % (t, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-9_5-Answers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
